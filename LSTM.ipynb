{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import time, random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from lstm import LSTMSentiment\n",
    "from bilstm import BiLSTMSentiment\n",
    "from torchtext import data\n",
    "import numpy as np\n",
    "import argparse\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_accuracy(truth, pred):\n",
    "    assert len(truth) == len(pred)\n",
    "    return accuracy_score(truth,pred)\n",
    "\n",
    "def get_f1(truth,pred):\n",
    "    assert len(truth) == len(pred)\n",
    "    return f1_score(truth,pred,average='weighted')\n",
    "\n",
    "def train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch):\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    truth_res = []\n",
    "    pred_res = []\n",
    "    count = 0\n",
    "    for batch in tqdm(train_iter, desc='Train epoch '+str(epoch+1)):\n",
    "        sent, label = batch.text, batch.label\n",
    "        label.data.sub_(1)\n",
    "        truth_res += list(label.data)\n",
    "        model.batch_size = len(label.data)\n",
    "        model.hidden = model.init_hidden()\n",
    "        pred = model(sent)\n",
    "        pred_label = pred.data.max(1)[1].numpy()\n",
    "        pred_res += [x for x in pred_label]\n",
    "        model.zero_grad()\n",
    "        loss = loss_function(pred, label)\n",
    "        avg_loss += loss.data[0]\n",
    "        count += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss /= len(train_iter)\n",
    "    acc = get_accuracy(truth_res, pred_res)\n",
    "    f1 = get_f1(truth_res, pred_res)\n",
    "    return avg_loss, acc,f1\n",
    "\n",
    "\n",
    "def train_epoch(model, train_iter, loss_function, optimizer):\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    truth_res = []\n",
    "    pred_res = []\n",
    "    count = 0\n",
    "    for batch in train_iter:\n",
    "        sent, label = batch.text, batch.label\n",
    "        label.data.sub_(1)\n",
    "        truth_res += list(label.data)\n",
    "        model.batch_size = len(label.data)\n",
    "        model.hidden = model.init_hidden()\n",
    "        pred = model(sent)\n",
    "        pred_label = pred.data.max(1)[1].numpy()\n",
    "        pred_res += [x for x in pred_label]\n",
    "        model.zero_grad()\n",
    "        loss = loss_function(pred, label)\n",
    "        avg_loss += loss.data[0]\n",
    "        count += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss /= len(train_iter)\n",
    "    acc = get_accuracy(truth_res, pred_res)\n",
    "    f1 = get_f1(truth_res, pred_res)\n",
    "    return avg_loss, acc,f1\n",
    "\n",
    "\n",
    "def evaluate(model, data, loss_function, name):\n",
    "    model.eval()\n",
    "    avg_loss = 0.0\n",
    "    truth_res = []\n",
    "    pred_res = []\n",
    "    for batch in data:\n",
    "        sent, label = batch.text, batch.label\n",
    "        label.data.sub_(1)\n",
    "        truth_res += list(label.data)\n",
    "        model.batch_size = len(label.data)\n",
    "        model.hidden = model.init_hidden()\n",
    "        pred = model(sent)\n",
    "        pred_label = pred.data.max(1)[1].numpy()\n",
    "        pred_res += [x for x in pred_label]\n",
    "        loss = loss_function(pred, label)\n",
    "        avg_loss += loss.data[0]\n",
    "    avg_loss /= len(data)\n",
    "    acc = get_accuracy(truth_res, pred_res)\n",
    "    f1 = get_f1(truth_res, pred_res)\n",
    "    print(name + ': loss %.2f acc %.1f f1 %.2f' % (avg_loss, acc*100,f1))\n",
    "    return acc,f1\n",
    "\n",
    "\n",
    "def load_sst(text_field, label_field, batch_size):\n",
    "    train, dev, test = data.TabularDataset.splits(path='./data/SST2/', train='train.csv',\n",
    "                                                  validation='dev.csv', test='test.csv', format='csv',\n",
    "                                                  fields=[('text', text_field), ('label', label_field)])\n",
    "    text_field.build_vocab(train, dev, test)\n",
    "    label_field.build_vocab(train, dev, test)\n",
    "    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n",
    "                batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=-1)\n",
    "    return train_iter, dev_iter, test_iter\n",
    "\n",
    "\n",
    "# def adjust_learning_rate(learning_rate, optimizer, epoch):\n",
    "#     lr = learning_rate * (0.1 ** (epoch // 10))\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "#     return optimizer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 150\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "timestamp = str(int(time.time()))\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "\n",
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freqs': Counter({'0': 19347,\n",
       "          '1': 9808,\n",
       "          '2': 730,\n",
       "          '3': 153,\n",
       "          '4': 906,\n",
       "          '5': 1187,\n",
       "          'label': 3}),\n",
       " 'itos': ['<unk>', '0', '1', '5', '4', '2', '3', 'label'],\n",
       " 'stoi': defaultdict(<function torchtext.vocab._default_unk_index>,\n",
       "             {'0': 1,\n",
       "              '1': 2,\n",
       "              '2': 5,\n",
       "              '3': 6,\n",
       "              '4': 4,\n",
       "              '5': 3,\n",
       "              '<unk>': 0,\n",
       "              'label': 7}),\n",
       " 'vectors': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(label_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji dictionary load successfully\n",
      "\\U0001f454\n",
      "\\U0001f300\n",
      "\\U0001f6be\n",
      "\\U0001f479\n",
      "\\U0001f6bb\n",
      "\\U0001f46c\n",
      "\\U0001f3a7\n",
      "\\U0001f43d\n",
      "\\U0001f69c\n",
      "\\u264b\n",
      "\\U0001f4c5\n",
      "\\U0001f488\n",
      "\\U0001f378\n",
      "\\U0001f937\n",
      "\\U0001f302\n",
      "\\U0001f693\n",
      "\\U0001f364\n",
      "\\U0001f498\n",
      "\\U0001f694\n",
      "\\U0001f45a\n",
      "\\U0001f427\n",
      "\\U0001f365\n",
      "\\U0001f375\n",
      "\\U0001f453\n",
      "\\u26d4\n",
      "\\U0001f615\n",
      "\\U0001f38e\n",
      "\\U0001f3ca\\U0001f3fb\n",
      "\\u2757\n",
      "\\U0001f4ad\n",
      "\\U0001f4ac\n",
      "\\u2696\n",
      "\\U0001f1ee\\U0001f1e9\n",
      "\\U0001f621\n",
      "\\U0001f1e8\\U0001f1ed\n",
      "\\U0001f366\n",
      "\\U0001f310\n",
      "\\U0001f3a1\n",
      "\\U0001f513\n",
      "\\U0001f3bb\n",
      "\\U0001f639\n",
      "\\U0001f47d\n",
      "\\U0001f31d\n",
      "\\U0001f1ed\\U0001f1fa\n",
      "\\U0001f406\n",
      "\\U0001f494\n",
      "\\U0001f447\\U0001f3fd\n",
      "\\U0001f346\n",
      "\\U0001f416\n",
      "\\U0001f62e\n",
      "\\u231a\n",
      "\\U0001f47b\n",
      "\\U0001f5fb\n",
      "\\U0001f1e8\\U0001f1fa\n",
      "\\U0001f61f\n",
      "\\U0001f4a3\n",
      "\\U0001f481\n",
      "\\U0001f980\n",
      "\\U0001f3a9\n",
      "\\U0001f449\\U0001f3fe\n",
      "\\U0001f64a\n",
      "\\U0001f35a\n",
      "\\U0001f359\n",
      "\\U0001f6af\n",
      "\\U0001f1eb\\U0001f1f7\n",
      "\\U0001f478\\U0001f3fc\n",
      "\\U0001f63f\n",
      "\\U0001f632\n",
      "\\U0001f6ac\n",
      "\\U0001f485\n",
      "\\U0001f3c0\n",
      "\\U0001f377\n",
      "\\U0001f648\n",
      "\\U0001f46d\n",
      "\\U0001f36f\n",
      "\\U0001f3f0\n",
      "\\U0001f5a8\n",
      "\\U0001f368\n",
      "\\U0001f197\n",
      "\\U0001f629\n",
      "\\U0001f389\n",
      "\\U0001f910\n",
      "\\U0001f3e3\n",
      "\\U0001f339\n",
      "\\U0001f32f\n",
      "\\U0001f386\n",
      "\\U0001f52e\n",
      "\\U0001f64c\n",
      "\\U0001f646\n",
      "\\U0001f392\n",
      "\\U0001f486\n",
      "\\U0001f530\n",
      "\\U0001f31c\n",
      "\\U0001f315\n",
      "\\U0001f391\n",
      "\\U0001f633\n",
      "\\u2693\n",
      "\\U0001f42b\n",
      "\\U0001f442\n",
      "\\U0001f483\n",
      "\\U0001f43c\n",
      "\\U0001f363\n",
      "\\U0001f3e7\n",
      "\\U0001f3a0\n",
      "\\U0001f334\n",
      "\\U0001f60f\n",
      "\\u26bd\n",
      "\\U0001f3eb\n",
      "\\U0001f603\n",
      "\\U0001f512\n",
      "\\u26fa\n",
      "\\U0001f4b5\n",
      "\\U0001f37a\n",
      "\\U0001f480\n",
      "\\U0001f305\n",
      "\\U0001f514\n",
      "\\U0001f489\n",
      "\\U0001f4af\n",
      "\\U0001f355\n",
      "\\U0001f463\n",
      "\\U0001f34c\n",
      "\\U0001f438\n",
      "\\U0001f36e\n",
      "\\U0001f49e\n",
      "\\U0001f1f3\\U0001f1ec\n",
      "\\U0001f6a6\n",
      "\\U0001f6a3\n",
      "\\U0001f495\n",
      "\\U0001f43e\n",
      "\\U0001f3c2\n",
      "\\U0001f44e\n",
      "\\U0001f400\n",
      "\\U0001f63b\n",
      "\\U0001f388\n",
      "\\U0001f405\n",
      "\\U0001f983\n",
      "\\U0001f40c\n",
      "\\U0001f3cb\n",
      "\\U0001f30e\n",
      "\\U0001f602\n",
      "\\U0001f321\n",
      "\\U0001f50f\n",
      "\\U0001f619\n",
      "\\U0001f445\n",
      "\\U0001f578\n",
      "\\U0001f1e9\\U0001f1ea\n",
      "\\U0001f379\n",
      "\\U0001f61b\n",
      "\\U0001f3cd\n",
      "\\U0001f492\n",
      "\\U0001f46f\n",
      "\\U0001f612\n",
      "\\U0001f50c\n",
      "\\U0001f311\n",
      "\\U0001f6a4\n",
      "\\U0001f3d3\n",
      "\\U0001f373\n",
      "\\U0001f354\n",
      "\\U0001f600\n",
      "\\U0001f64f\n",
      "\\U0001f335\n",
      "\\U0001f34b\n",
      "\\u2618\n",
      "\\U0001f340\n",
      "\\U0001f3ec\n",
      "\\U0001f689\n",
      "\\U0001f357\n",
      "\\U0001f596\\U0001f3fd\n",
      "\\u26fd\n",
      "\\U0001f331\n",
      "\\U0001f4b4\n",
      "\\U0001f42d\n",
      "\\u26c4\n",
      "\\U0001f304\n",
      "\\U0001f3b0\n",
      "\\U0001f596\\U0001f3fc\n",
      "\\U0001f424\n",
      "\\U0001f68c\n",
      "\\U0001f3aa\n",
      "\\U0001f385\n",
      "\\U0001f473\n",
      "\\U0001f374\n",
      "\\U0001f470\n",
      "\\U0001f4bf\n",
      "\\U0001f642\n",
      "\\U0001f393\n",
      "\\U0001f6b5\n",
      "\\U0001f51f\n",
      "\\U0001f423\n",
      "\\U0001f1f8\\U0001f1fb\n",
      "\\U0001f645\\U0001f3fb\n",
      "\\U0001f3d2\n",
      "\\U0001f1f5\\U0001f1ec\n",
      "\\U0001f4a0\n",
      "\\U0001f3be\n",
      "\\U0001f3b3\n",
      "\\U0001f47a\n",
      "\\U0001f926\n",
      "\\U0001f1e9\\U0001f1f4\n",
      "\\U0001f682\n",
      "\\U0001f4b7\n",
      "\\U0001f34f\n",
      "\\U0001f51c\n",
      "\\u2721\n",
      "\\U0001f472\n",
      "\\U0001f698\n",
      "\\U0001f4cd\n",
      "\\U0001f320\n",
      "\\U0001f383\n",
      "\\U0001f3e9\n",
      "\\U0001f4b3\n",
      "\\U0001f60a\n",
      "\\U0001f35f\n",
      "\\u2614\n",
      "\\U0001f1ec\\U0001f1e7\n",
      "\\U0001f45f\n",
      "\\U0001f31b\n",
      "\\U0001f3f7\n",
      "\\U0001f4ae\n",
      "\\U0001f44b\n",
      "\\U0001f549\n",
      "\\U0001f443\n",
      "\\U0001f3b1\n",
      "\\U0001f353\n",
      "\\U0001f307\n",
      "\\U0001f3ab\n",
      "\\U0001f4a7\n",
      "\\U0001f60e\n",
      "\\U0001f46b\n",
      "\\U0001f60b\n",
      "\\U0001f596\n",
      "\\U0001f6ba\n",
      "\\U0001f616\n",
      "\\U0001f301\n",
      "\\U0001f415\n",
      "\\u264a\n",
      "\\U0001f41f\n",
      "\\u2648\n",
      "\\U0001f41d\n",
      "\\U0001f1ee\\U0001f1f3\n",
      "\\u270b\n",
      "\\U0001f3c7\n",
      "\\U0001f645\n",
      "\\U0001f33b\n",
      "9\\ufe0f\\u20e3\n",
      "\\U0001f44f\n",
      "\\U0001f309\n",
      "\\U0001f47f\n",
      "\\U0001f390\n",
      "\\U0001f1ea\\U0001f1f8\n",
      "\\U0001f44d\\U0001f3ff\n",
      "\\U0001f370\n",
      "\\U0001f6a1\n",
      "\\U0001f3af\n",
      "\\U0001f62a\n",
      "\\U0001f64b\n",
      "\\U0001f634\n",
      "\\U0001f614\n",
      "\\u26f7\n",
      "\\U0001f631\n",
      "\\U0001f630\n",
      "\\U0001f490\n",
      "\\U0001f6b0\n",
      "\\U0001f31a\n",
      "\\U0001f36c\n",
      "\\U0001f509\n",
      "\\U0001f3d0\n",
      "\\U0001f369\n",
      "\\U0001f49c\n",
      "\\U0001f6c1\n",
      "\\U0001f382\n",
      "\\U0001f3b7\n",
      "\\U0001f640\n",
      "\\U0001f308\n",
      "\\U0001f469\n",
      "\\U0001f922\n",
      "\\U0001f3a8\n",
      "\\U0001f4a4\n",
      "\\u26b0\n",
      "\\U0001f6b4\n",
      "\\U0001f3bd\n",
      "\\U0001f635\n",
      "\\U0001f625\n",
      "\\U0001f441\n",
      "\\U0001f43a\n",
      "\\U0001f699\n",
      "\\U0001f35e\n",
      "\\U0001f3b8\n",
      "\\U0001f36d\n",
      "\\U0001f30c\n",
      "\\U0001f48f\n",
      "\\U0001f338\n",
      "\\U0001f456\n",
      "\\U0001f44a\\U0001f3fd\n",
      "\\U0001f446\n",
      "\\U0001f6cb\n",
      "\\U0001f33e\n",
      "\\U0001f3c6\n",
      "\\U0001f31e\n",
      "\\U0001f30b\n",
      "\\U0001f601\n",
      "\\U0001f3c4\n",
      "\\U0001f469\\U0001f3fe\n",
      "\\U0001f645\\U0001f3fc\n",
      "\\U0001f3ee\n",
      "\\U0001f604\n",
      "\\U0001f3a3\n",
      "\\U0001f35b\n",
      "\\U0001f4ce\n",
      "\\U0001f69b\n",
      "\\U0001f595\n",
      "\\U0001f42a\n",
      "\\U0001f681\n",
      "\\U0001f605\n",
      "\\U0001f3ad\n",
      "\\U0001f362\n",
      "\\U0001f21a\n",
      "\\U0001f474\n",
      "\\U0001f3e0\n",
      "\\U0001f5dd\n",
      "\\U0001f4bd\n",
      "\\U0001f3b9\n",
      "\\U0001f608\n",
      "\\U0001f1fb\\U0001f1f3\n",
      "\\U0001f4f0\n",
      "7\\ufe0f\\u20e3\n",
      "\\U0001f37b\n",
      "\\U0001f609\n",
      "\\U0001f48d\n",
      "\\U0001f6b6\n",
      "\\U0001f647\\U0001f3fd\n",
      "\\U0001f41e\n",
      "\\U0001f372\n",
      "\\U0001f349\n",
      "\\U0001f432\n",
      "\\U0001f464\n",
      "\\U0001f61e\n",
      "\\U0001f3b6\n",
      "\\U0001f444\n",
      "\\U0001f5ff\n",
      "\\U0001f306\n",
      "\\U0001f680\n",
      "\\U0001f471\\U0001f3ff\n",
      "\\U0001f37c\n",
      "\\U0001f3de\n",
      "\\U0001f40d\n",
      "\\U0001f4e6\n",
      "\\U0001f1f5\\U0001f1f8\n",
      "\\U0001f303\n",
      "\\U0001f3ac\n",
      "\\U0001f637\n",
      "\\U0001f452\n",
      "\\U0001f4f2\n",
      "\\U0001f525\n",
      "\\U0001f3a2\n",
      "\\U0001f428\n",
      "\\U0001f4c6\n",
      "\\u2b55\n",
      "\\U0001f3c9\n",
      "\\U0001f613\n",
      "\\U0001f3dc\n",
      "\\U0001f33f\n",
      "\\U0001f3e8\n",
      "\\U0001f38f\n",
      "\\U0001f1ec\\U0001f1fe\n",
      "\\U0001f6bd\n",
      "\\U0001f450\n",
      "\\U0001f407\n",
      "\\U0001f3b2\n",
      "\\U0001f422\n",
      "\\U0001f638\n",
      "\\U0001f5c3\n",
      "\\U0001f575\n",
      "\\U0001f371\n",
      "\\U0001f409\n",
      "\\U0001f63a\n",
      "\\U0001f62b\n",
      "\\U0001f32d\n",
      "\\U0001f367\n",
      "\\U0001f35d\n",
      "\\U0001f64d\n",
      "\\U0001f649\n",
      "\\U0001f1f5\\U0001f1ed\n",
      "\\U0001f577\n",
      "\\U0001f5bc\n",
      "\\U0001f628\n",
      "\\U0001f4bb\n",
      "\\U0001f508\n",
      "\\U0001f1e9\\U0001f1ff\n",
      "\\U0001f4b8\n",
      "\\U0001f3ca\n",
      "\\U0001f376\n",
      "\\U0001f6a2\n",
      "\\U0001f3c1\n",
      "\\U0001f647\n",
      "\\U0001f1ed\\U0001f1f9\n",
      "\\U0001f44a\\U0001f3fc\n",
      "\\U0001f624\n",
      "\\U0001f1ee\\U0001f1f1\n",
      "\\U0001f437\n",
      "\\U0001f4b0\n",
      "\\U0001f446\\U0001f3ff\n",
      "\\U0001f455\n",
      "\\U0001f50e\n",
      "\\U0001f3cf\n",
      "\\U0001f935\n",
      "\\U0001f483\\U0001f3fd\n",
      "\\U0001f449\\U0001f3fc\n",
      "\\U0001f499\n",
      "\\U0001f617\n",
      "\\U0001f6d0\n",
      "\\U0001f1fb\\U0001f1e6\n",
      "\\U0001f44c\n",
      "\\U0001f6a9\n",
      "\\U0001f944\n",
      "\\U0001f38b\n",
      "\\u270a\n",
      "\\u26a1\n",
      "\\U0001f4ff\n",
      "\\U0001f332\n",
      "\\U0001f440\n",
      "\\U0001f692\n",
      "\\U0001f60c\n",
      "\\U0001f917\n",
      "\\U0001f1fb\\U0001f1ea\n",
      "\\U0001f384\n",
      "\\U0001f4e9\n",
      "\\U0001f356\n",
      "\\U0001f987\n",
      "\\U0001f1e8\\U0001f1fb\n",
      "\\U0001f4ab\n",
      "\\U0001f34d\n",
      "\\U0001f3a4\n",
      "\\U0001f959\n",
      "\\U0001f688\n",
      "\\U0001f62c\n",
      "\\U0001f325\n",
      "\\U0001f40e\n",
      "\\U0001f57a\n",
      "\\U0001f52a\n",
      "\\u270a\\U0001f3fd\n",
      "\\U0001f3bf\n",
      "\\U0001f33c\n",
      "\\U0001f519\n",
      "\\U0001f3ae\n",
      "\\u26aa\n",
      "\\U0001f5a4\n",
      "\\U0001f3bc\n",
      "\\U0001f1ff\\U0001f1e6\n",
      "\\u274e\n",
      "\\U0001f62d\n",
      "\\U0001f4f3\n",
      "\\U0001f447\\U0001f3fe\n",
      "\\U0001f3b5\n",
      "\\U0001f618\n",
      "\\U0001f64f\\U0001f3fc\n",
      "\\U0001f61c\n",
      "\\U0001f43b\n",
      "\\U0001f318\n",
      "\\U0001f1ea\\U0001f1fa\n",
      "\\U0001f42e\n",
      "\\U0001f3e5\n",
      "\\U0001f429\n",
      "\\U0001f31f\n",
      "\\U0001f487\n",
      "\\U0001f381\n",
      "\\U0001f34e\n",
      "\\U0001f6a8\n",
      "\\U0001f330\n",
      "\\u2653\n",
      "\\U0001f4f9\n",
      "\\U0001f30d\n",
      "\\U0001f1e7\\U0001f1e7\n",
      "\\U0001f4f1\n",
      "\\U0001f647\\U0001f3fb\n",
      "\\U0001f41b\n",
      "\\U0001f1ef\\U0001f1f5\n",
      "\\u2705\n",
      "\\U0001f52b\n",
      "\\U0001f6ab\n",
      "\\U0001f412\n",
      "\\U0001f468\\u200d\\U0001f469\\u200d\\U0001f467\\u200d\\U0001f466\n",
      "\\U0001f63c\n",
      "\\U0001f1f9\\U0001f1f3\n",
      "\\U0001f476\\U0001f3fd\n",
      "\\U0001f56f\n",
      "\\U0001f60d\n",
      "\\U0001f47e\n",
      "\\U0001f683\n",
      "\\U0001f39b\n",
      "\\U0001f933\n",
      "\\U0001f326\n",
      "\\U0001f3ea\n",
      "\\U0001f4dd\n",
      "\\U0001f1e7\\U0001f1f4\n",
      "\\U0001f1f5\\U0001f1ea\n",
      "\\u26f8\n",
      "\\U0001f4a9\n",
      "\\U0001f985\n",
      "\\U0001f920\n",
      "\\U0001f5c2\n",
      "\\U0001f448\\U0001f3fe\n",
      "\\U0001f337\n",
      "\\U0001f574\n",
      "\\U0001f468\\u200d\\u2764\\ufe0f\\u200d\\U0001f48b\\u200d\\U0001f468\n",
      "\\U0001f38a\n",
      "\\U0001f3ce\n",
      "\\U0001f64c\\U0001f3fd\n",
      "\\U0001f6a7\n",
      "\\U0001f49f\n",
      "\\U0001f1f8\\U0001f1ea\n",
      "\\U0001f448\\U0001f3fb\n",
      "\\U0001f4a5\n",
      "\\U0001f58c\n",
      "\\U0001f44d\\U0001f3fe\n",
      "\\U0001f485\\U0001f3fb\n",
      "\\U0001f497\n",
      "\\U0001f4a1\n",
      "\\U0001f32b\n",
      "\\U0001f32c\n",
      "\\u23f0\n",
      "\\u262f\n",
      "\\U0001f4aa\n",
      "\\U0001f511\n",
      "\\U0001f48a\n",
      "\\U0001f469\\u200d\\u2764\\ufe0f\\u200d\\U0001f469\n",
      "\\U0001f590\n",
      "\\U0001f417\n",
      "\\U0001f3c3\n",
      "\\U0001f1e8\\U0001f1f3\n",
      "\\U0001f45b\n",
      "\\U0001f6bf\n",
      "\\U0001f414\n",
      "\\U0001f50d\n",
      "\\U0001f430\n",
      "\\U0001f468\\U0001f3ff\n",
      "\\U0001f91e\n",
      "\\U0001f30a\n",
      "\\U0001f504\n",
      "\\U0001f3ba\n",
      "\\U0001f6cc\n",
      "\\U0001f3c4\\U0001f3ff\n",
      "\\U0001f91d\n",
      "\\u2615\n",
      "\\U0001f64f\\U0001f3fe\n",
      "\\U0001f64c\\U0001f3ff\n",
      "\\U0001f431\n",
      "\\U0001f4a2\n",
      "\\U0001f3a6\n",
      "\\U0001f380\n",
      "\\U0001f4da\n",
      "\\U0001f33a\n",
      "\\U0001f34a\n",
      "\\U0001f485\\U0001f3fc\n",
      "\\U0001f419\n",
      "\\U0001f342\n",
      "\\U0001f636\n",
      "\\U0001f610\n",
      "\\U0001f350\n",
      "\\U0001f3c5\n",
      "\\u274c\n",
      "\\U0001f923\n",
      "\\u2796\n",
      "\\U0001f462\n",
      "\\U0001f3f5\n",
      "\\U0001f5fd\n",
      "\\U0001f344\n",
      "\\U0001f447\n",
      "\\U0001f1f8\\U0001f1e6\n",
      "\\U0001f37f\n",
      "\\U0001f1f8\\U0001f1ec\n",
      "\\U0001f425\n",
      "\\U0001f921\n",
      "\\u26f0\n",
      "\\U0001f5b1\n",
      "\\U0001f411\n",
      "\\U0001f3a5\n",
      "\\U0001f3e6\n",
      "\\U0001f319\n",
      "\\U0001f004\n",
      "\\U0001f351\n",
      "\\U0001f528\n",
      "\\U0001f30f\n",
      "\\U0001f44e\\U0001f3fc\n",
      "\\U0001f4aa\\U0001f3ff\n",
      "\\U0001f1f2\\U0001f1f9\n",
      "\\U0001f6cd\n",
      "\\u26ea\n",
      "\\U0001f1ed\\U0001f1f7\n",
      "\\U0001f481\\U0001f3fe\n",
      "\\U0001f448\\U0001f3fc\n",
      "\\U0001f478\n",
      "\\U0001f4fc\n",
      "\\U0001f470\\U0001f3fc\n",
      "\\U0001f46a\n",
      "\\U0001f918\n",
      "\\U0001f341\n",
      "\\U0001f459\n",
      "\\u26f2\n",
      "\\U0001f6b8\n",
      "\\U0001f646\\U0001f3fb\n",
      "\\u270a\\U0001f3fe\n",
      "\\U0001f49a\n",
      "\\U0001f333\n",
      "\\U0001f4fb\n",
      "\\U0001f435\n",
      "\\U0001f449\\U0001f3fd\n",
      "\\U0001f61d\n",
      "\\U0001f49b\n",
      "\\U0001f4e7\n",
      "\\U0001f950\n",
      "\\U0001f410\n",
      "\\U0001f61a\n",
      "\\U0001f4d6\n",
      "\\U0001f3c8\n",
      "\\U0001f626\n",
      "\\U0001f68b\n",
      "\\U0001f439\n",
      "\\U0001f6bc\n",
      "\\U0001f1e6\\U0001f1fa\n",
      "\\U0001f1f3\\U0001f1f1\n",
      "\\U0001f684\n",
      "\\U0001f6e5\n",
      "\\U0001f925\n",
      "\\U0001f44c\\U0001f3ff\n",
      "\\U0001f981\n",
      "\\U0001f4b2\n",
      "\\U0001f1f0\\U0001f1f7\n",
      "\\u2b50\n",
      "\\u270a\\U0001f3ff\n",
      "\\U0001f46e\\U0001f3fd\n",
      "\\u270b\\U0001f3fb\n",
      "\\U0001f3ef\n",
      "\\U0001f49d\n",
      "\\U0001f3d8\n",
      "\\U0001f32a\n",
      "\\U0001f448\n",
      "\\U0001f916\n",
      "\\U0001f4f5\n",
      "\\U0001f1e8\\U0001f1f1\n",
      "\\U0001f6a0\n",
      "\\U0001f1f9\\U0001f1ed\n",
      "\\U0001f4a8\n",
      "\\U0001f1f9\\U0001f1f7\n",
      "\\U0001f36a\n",
      "\\U0001f620\n",
      "\\U0001f4aa\\U0001f3fd\n",
      "\\U0001f6c0\n",
      "\\U0001f43f\n",
      "\\U0001f44e\\U0001f3fb\n",
      "\\U0001f343\n",
      "\\u26c5\n",
      "\\U0001f36b\n",
      "\\u2620\n",
      "\\U0001f686\n",
      "\\U0001f69a\n",
      "\\U0001f449\n",
      "\\U0001f915\n",
      "\\U0001f469\\u200d\\U0001f469\\u200d\\U0001f466\\u200d\\U0001f466\n",
      "\\U0001f44d\n",
      "\\U0001f1e8\\U0001f1fe\n",
      "\\U0001f958\n",
      "\\U0001f408\n",
      "\\U0001f3d4\n",
      "8\\ufe0f\\u20e3\n",
      "\\u2753\n",
      "\\U0001f3d5\n",
      "\\U0001f250\n",
      "\\U0001f1ee\\U0001f1f9\n",
      "\\U0001f4eb\n",
      "\\U0001f41a\n",
      "\\U0001f526\n",
      "\\U0001f573\n",
      "\\U0001f1eb\\U0001f1ee\n",
      "\\U0001f44f\\U0001f3ff\n",
      "\\U0001f1ee\\U0001f1ea\n",
      "\\U0001f63d\n",
      "\\U0001f468\\u200d\\U0001f469\\u200d\\U0001f467\\u200d\\U0001f467\n",
      "\\U0001f63e\n",
      "\\U0001f64b\\U0001f3fd\n",
      "\\U0001f446\\U0001f3fd\n",
      "\\U0001f5e1\n",
      "\\U0001f478\\U0001f3fe\n",
      "\\u26c8\n",
      "\\U0001f986\n",
      "\\U0001f457\n",
      "\\U0001f467\\U0001f3fe\n",
      "\\U0001f570\n",
      "\\U0001f396\n",
      "\\U0001f5e3\n",
      "\\U0001f47c\\U0001f3fb\n",
      "\\U0001f538\n",
      "\\U0001f0cf\n",
      "\\U0001f58a\n",
      "\\U0001f336\n",
      "\\U0001f952\n",
      "\\U0001f622\n",
      "\\U0001f4be\n",
      "\\U0001f98f\n",
      "\\U0001f1fa\\U0001f1f8\n",
      "\\U0001f62f\n",
      "\\u2694\n",
      "\\U0001f347\n",
      "\\U0001f475\\U0001f3fc\n",
      "\\U0001f943\n",
      "\\U0001f485\\U0001f3fd\n",
      "\\U0001f68a\n",
      "\\U0001f911\n",
      "\\U0001f4b9\n",
      "\\U0001f451\n",
      "\\u23f1\n",
      "\\U0001f1f2\\U0001f1fd\n",
      "\\U0001f4e1\n",
      "\\U0001f192\n",
      "\\U0001f5fe\n",
      "\\U0001f1f1\\U0001f1e7\n",
      "\\U0001f48b\n",
      "\\U0001f461\n",
      "\\U0001f44d\\U0001f3fb\n",
      "\\U0001f22f\n",
      "\\U0001f44f\\U0001f3fe\n",
      "\\U0001f434\n",
      "\\U0001f487\\U0001f3fc\n",
      "\\U0001f64b\\U0001f3fb\n",
      "\\U0001f4bc\n",
      "\\U0001f1ec\\U0001f1f9\n",
      "\\U0001f644\n",
      "\\U0001f1ef\\U0001f1f2\n",
      "\\U0001f940\n",
      "\\U0001f493\n",
      "\\U0001f6f3\n",
      "\\U0001f1f3\\U0001f1f4\n",
      "\\U0001f51b\n",
      "\\U0001f58b\n",
      "\\U0001f44c\\U0001f3fe\n",
      "\\U0001f4ee\n",
      "\\U0001f468\n",
      "\\U0001f611\n",
      "\\U0001f4d5\n",
      "\\U0001f46e\n",
      "\\U0001f627\n",
      "\\U0001f1e6\\U0001f1f7\n",
      "\\U0001f5fa\n",
      "\\U0001f44a\n",
      "\\U0001f193\n",
      "\\U0001f40b\n",
      "\\U0001f5a5\n",
      "\\U0001f477\n",
      "\\u270b\\U0001f3fd\n",
      "\\U0001f413\n",
      "\\u262e\n",
      "\\U0001f448\\U0001f3ff\n",
      "\\U0001f955\n",
      "\\U0001f436\n",
      "\\U0001f927\n",
      "\\U0001f6cf\n",
      "\\U0001f51a\n",
      "\\U0001f50a\n",
      "\\U0001f697\n",
      "\\U0001f1f7\\U0001f1fa\n",
      "\\U0001f506\n",
      "\\U0001f510\n",
      "\\u2602\n",
      "\\U0001f4cc\n",
      "\\u26f3\n",
      "\\U0001f4c0\n",
      "\\u271d\n",
      "\\U0001f468\\u200d\\u2764\\ufe0f\\u200d\\U0001f468\n",
      "\\U0001f44b\\U0001f3fc\n",
      "\\U0001f6c0\\U0001f3fd\n",
      "\\U0001f643\n",
      "\\U0001f607\n",
      "\\u26ab\n",
      "\\U0001f4d3\n",
      "\\U0001f37d\n",
      "\\U0001f4f4\n",
      "\\u26d3\n",
      "\\U0001f4fa\n",
      "\\U0001f4e2\n",
      "\\U0001f39f\n",
      "\\U0001f553\n",
      "\\U0001f51d\n",
      "\\U0001f239\n",
      "\\U0001f47c\n",
      "\\U0001f501\n",
      "\\U0001f35c\n",
      "\\U0001f44d\\U0001f3fc\n",
      "\\U0001f491\n",
      "\\U0001f1e7\\U0001f1ef\n",
      "\\U0001f460\n",
      "\\U0001f517\n",
      "\\U0001f48e\n",
      "\\u2728\n",
      "\\U0001f988\n",
      "\\U0001f471\n",
      "\\U0001f537\n",
      "\\U0001f234\n",
      "\\U0001f420\n",
      "\\U0001f467\\U0001f3fb\n",
      "\\U0001f91a\n",
      "\\U0001f470\\U0001f3fb\n",
      "\\U0001f641\n",
      "\\U0001f1f2\\U0001f1f7\n",
      "\\U0001f474\\U0001f3fb\n",
      "\\U0001f1e8\\U0001f1e6\n",
      "\\U0001f596\\U0001f3fb\n",
      "\\U0001f48c\n",
      "\\U0001f484\n",
      "\\U0001f1e6\\U0001f1ea\n",
      "\\U0001f4a6\n",
      "\\U0001f924\n",
      "\\U0001f42f\n",
      "\\U0001f478\\U0001f3fb\n",
      "\\U0001f44d\\U0001f3fd\n",
      "\\U0001f4e0\n",
      "\\U0001f9c0\n",
      "\\U0001f348\n",
      "1\\ufe0f\\u20e3\n",
      "\\U0001f606\n",
      "\\U0001f198\n",
      "\\U0001f1f3\\U0001f1ff\n",
      "\\u2639\n",
      "\\U0001f4aa\\U0001f3fb\n",
      "\\u2604\n",
      "\\U0001f447\\U0001f3fb\n",
      "\\U0001f483\\U0001f3ff\n",
      "\\U0001f4c4\n",
      "\\U0001f476\n",
      "\\U0001f37e\n",
      "\\U0001f1e8\\U0001f1ff\n",
      "\\U0001f531\n",
      "\\U0001f4f7\n",
      "\\u2763\n",
      "\\U0001f475\n",
      "\\U0001f1ec\\U0001f1f7\n",
      "\\u2755\n",
      "\\U0001f98a\n",
      "\\U0001f576\n",
      "\\U0001f1e7\\U0001f1f7\n",
      "\\U0001f1f5\\U0001f1f9\n",
      "\\U0001f54b\n",
      "\\U0001f44f\\U0001f3fc\n",
      "\\U0001f40a\n",
      "\\U0001f6ec\n",
      "\\U0001f3f9\n",
      "\\U0001f32e\n",
      "\\U0001f53d\n",
      "\\u27bf\n",
      "\\U0001f5f3\n",
      "\\U0001f469\\U0001f3fc\n",
      "\\U0001f914\n",
      "\\U0001f483\\U0001f3fb\n",
      "\\U0001f6f0\n",
      "\\U0001f1f5\\U0001f1e6\n",
      "\\u26be\n",
      "\\U0001f691\n",
      "\\U0001f957\n",
      "\\U0001f552\n",
      "\\U0001f6e0\n",
      "\\U0001f352\n",
      "\\U0001f44c\\U0001f3fd\n",
      "\\U0001f466\n",
      "\\U0001f953\n",
      "\\U0001f478\\U0001f3fd\n",
      "\\U0001f3d9\n",
      "\\U0001f1fa\\U0001f1e6\n",
      "\\u27b0\n",
      "\\U0001f450\\U0001f3fb\n",
      "\\U0001f345\n",
      "\\U0001f982\n",
      "\\u23e9\n",
      "\\U0001f449\\U0001f3ff\n",
      "\\U0001f58d\n",
      "\\U0001f496\n",
      "\\U0001f989\n",
      "\\U0001f4d8\n",
      "\\U0001f4ca\n",
      "\\u270b\\U0001f3fc\n",
      "\\u26e9\n",
      "\\U0001f1e6\\U0001f1f1\n",
      "\\U0001f324\n",
      "\\U0001f1ef\\U0001f1f4\n",
      "\\U0001f6b2\n",
      "\\U0001f539\n",
      "\\U0001f3e1\n",
      "\\U0001f447\\U0001f3fc\n",
      "\\U0001f5d3\n",
      "\\U0001f483\\U0001f3fe\n",
      "\\U0001f44c\\U0001f3fb\n",
      "\\U0001f6d1\n",
      "\\U0001f45c\n",
      "\\U0001f1f1\\U0001f1ee\n",
      "\\U0001f623\n",
      "\\U0001f3c3\\U0001f3fb\n",
      "\\U0001f934\n",
      "\\U0001f64b\\U0001f3fc\n",
      "\\U0001f4e3\n",
      "\\u231b\n",
      "\\U0001f4de"
     ]
    }
   ],
   "source": [
    "#load dictionary\n",
    "import pickle\n",
    "emoji_dict =pickle.load(open('./data/SST2/emoji_dict.p','rb'))\n",
    "print(\"emoji dictionary load successfully\")\n",
    "# load embedding\n",
    "word_to_idx = text_field.vocab.stoi\n",
    "pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n",
    "pretrained_embeddings[0] = 0\n",
    "#word2vec = load_bin_vec('./data/GoogleNews-vectors-negative300.bin', word_to_idx)\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "emoji2vec =KeyedVectors.load_word2vec_format('./embedding/emoji2vec.bin', binary=True)\n",
    "\n",
    "for word in emoji2vec.vocab:\n",
    "    s = word.encode('unicode-escape').decode('ASCII')\n",
    "    if s in emoji_dict.keys():\n",
    "        print(s)\n",
    "        pretrained_embeddings[word_to_idx[emoji_dict[s]]-1] = emoji2vec[word]\n",
    "print(\"emoji2vec load successfully\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word2vec= KeyedVectors.load_word2vec_format('./embedding/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "for word in word2vec.vocab:\n",
    "    pretrained_embeddings[word_to_idx[word]-1] = word2vec[word]\n",
    "print(\"word2vec load successfully\")\n",
    "\n",
    "\n",
    "emoticon2vec = KeyedVectors.load_word2vec_format('./embedding/emoticon2vec.txt', binary=False)\n",
    "\n",
    "for word in emoticon2vec.vocab:\n",
    "    pretrained_embeddings[word_to_idx[word]-1] = emoticon2vec[word]\n",
    "print(\"emoticon2vec load successfully\")    \n",
    "print('Loading complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n",
    "                          use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "-0.1564  0.1313 -0.0573  ...   0.2062 -0.0458  0.1574\n",
       " 0.0801  0.1050  0.0498  ...   0.0037  0.0476 -0.0688\n",
       "          ...             ⋱             ...          \n",
       " 0.1075  0.0449  0.2172  ...  -0.1078  0.1145  0.2146\n",
       "-0.2470 -0.1418 -0.0502  ...  -0.0088 -0.0527 -0.1548\n",
       "-0.0400  0.0009 -0.0988  ...   0.0423 -0.0371 -0.0146\n",
       "[torch.FloatTensor of size 51322x300]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss function\n",
    "best_model = model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 1:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Writing to /Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/runs/1523664846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/lstm.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs = F.log_softmax(y)\n",
      "Train epoch 1: 100%|██████████| 4049/4049 [1:10:20<00:00,  1.04s/it]\n",
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.84 acc 67.0 f1 0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:89: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.19 acc 42.7 f1 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 2:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.24 acc 33.7 f1 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████| 4049/4049 [1:35:40<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.41 acc 86.0 f1 0.855\n",
      "Dev: loss 0.92 acc 59.3 f1 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 3:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.02 acc 50.5 f1 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████| 4049/4049 [1:23:58<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.21 acc 92.3 f1 0.922\n",
      "Dev: loss 0.78 acc 69.0 f1 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 4:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 0.80 acc 66.0 f1 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████| 4049/4049 [1:03:23<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.13 acc 94.2 f1 0.942\n",
      "Dev: loss 0.79 acc 71.1 f1 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 5:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 0.84 acc 68.2 f1 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████| 4049/4049 [56:04<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.11 acc 94.8 f1 0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 6:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.17 acc 62.5 f1 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████| 4049/4049 [3:25:20<00:00,  3.04s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.09 acc 95.0 f1 0.950\n",
      "Dev: loss 0.93 acc 72.2 f1 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 7:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 0.98 acc 69.4 f1 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████| 4049/4049 [2:59:05<00:00,  2.65s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.08 acc 95.2 f1 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 8:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.06 acc 70.0 f1 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████| 4049/4049 [54:36<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.08 acc 95.5 f1 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 9:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.16 acc 67.7 f1 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████| 4049/4049 [3:15:39<00:00,  2.90s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.08 acc 95.2 f1 0.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 10:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.53 acc 57.4 f1 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 10: 100%|██████████| 4049/4049 [1:13:20<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.07 acc 95.6 f1 0.955\n",
      "Dev: loss 1.09 acc 70.2 f1 0.71\n",
      "Final Test: loss 1.15 acc 66.8 f1 0.69\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss, acc,f1 = train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\n",
    "    tqdm.write('Train: loss %.2f acc %.1f f1 %.3f' % (avg_loss, acc*100,f1))\n",
    "    dev_acc , dev_f1= evaluate(model, dev_iter, loss_function, 'Dev')\n",
    "    if dev_acc > best_dev_acc:\n",
    "        if best_dev_acc > 0:\n",
    "            os.system('rm '+ out_dir + '/best_model' + '.pth')\n",
    "        best_dev_acc = dev_acc\n",
    "        best_model = model\n",
    "        torch.save(best_model.state_dict(), out_dir + '/best_model' + '.pth')\n",
    "        # evaluate on test with the best dev performance model\n",
    "        test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Test')\n",
    "test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Final Test')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# try different dim of hidden layer (after load dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 500\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "timestamp = str(int(time.time()))\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "\n",
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n",
    "                          use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "-0.1564  0.1313 -0.0573  ...   0.2062 -0.0458  0.1574\n",
       " 0.0801  0.1050  0.0498  ...   0.0037  0.0476 -0.0688\n",
       "          ...             ⋱             ...          \n",
       " 0.1075  0.0449  0.2172  ...  -0.1078  0.1145  0.2146\n",
       "-0.2470 -0.1418 -0.0502  ...  -0.0088 -0.0527 -0.1548\n",
       "-0.0400  0.0009 -0.0988  ...   0.0423 -0.0371 -0.0146\n",
       "[torch.FloatTensor of size 51322x300]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss function\n",
    "best_model = model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 1:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Writing to /Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/runs/1523730993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/lstm.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs = F.log_softmax(y)\n",
      "Train epoch 1: 100%|██████████| 4049/4049 [42:42<00:00,  1.58it/s]\n",
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.89 acc 65.0 f1 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:89: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.15 acc 65.0 f1 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 2:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.20 acc 62.5 f1 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████| 4049/4049 [1:14:23<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.48 acc 83.4 f1 0.822\n",
      "Dev: loss 0.87 acc 67.3 f1 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 3:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 0.94 acc 64.7 f1 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████| 4049/4049 [1:34:31<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.25 acc 91.2 f1 0.910\n",
      "Dev: loss 0.72 acc 74.5 f1 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 4:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 0.74 acc 72.8 f1 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████| 4049/4049 [2:34:58<00:00,  2.30s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.16 acc 93.6 f1 0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 5:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.36 acc 52.9 f1 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████| 4049/4049 [2:14:51<00:00,  2.00s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.12 acc 94.3 f1 0.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 6:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.01 acc 65.8 f1 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████| 4049/4049 [2:55:46<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.10 acc 94.9 f1 0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 7:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.14 acc 65.8 f1 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████| 4049/4049 [2:56:47<00:00,  2.62s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.09 acc 95.1 f1 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 8:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 0.89 acc 73.9 f1 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████| 4049/4049 [3:59:37<00:00,  3.55s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.08 acc 95.4 f1 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 9:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.02 acc 68.8 f1 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████| 4049/4049 [2:28:48<00:00,  2.21s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.08 acc 95.4 f1 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 10:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 0.93 acc 70.4 f1 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 10: 100%|██████████| 4049/4049 [2:10:45<00:00,  1.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.08 acc 95.5 f1 0.955\n",
      "Dev: loss 0.87 acc 72.7 f1 0.73\n",
      "Final Test: loss 0.89 acc 71.6 f1 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss, acc,f1 = train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\n",
    "    tqdm.write('Train: loss %.2f acc %.1f f1 %.3f' % (avg_loss, acc*100,f1))\n",
    "    dev_acc , dev_f1= evaluate(model, dev_iter, loss_function, 'Dev')\n",
    "    if dev_acc > best_dev_acc:\n",
    "        if best_dev_acc > 0:\n",
    "            os.system('rm '+ out_dir + '/best_model' + '.pth')\n",
    "        best_dev_acc = dev_acc\n",
    "        best_model = model\n",
    "        torch.save(best_model.state_dict(), out_dir + '/best_model' + '.pth')\n",
    "        # evaluate on test with the best dev performance model\n",
    "        test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Test')\n",
    "test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Final Test')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try L2 penalty on 500 hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 500\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "timestamp = str(int(time.time()))\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "\n",
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n",
    "                          use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0452  0.0593  0.0739  ...  -0.0481 -0.1746  0.1170\n",
       " 0.0801  0.1050  0.0498  ...   0.0037  0.0476 -0.0688\n",
       "          ...             ⋱             ...          \n",
       "-0.2312  0.0737 -0.1603  ...   0.2040  0.1060  0.1579\n",
       " 0.0512 -0.1998 -0.0526  ...   0.1661  0.1353  0.1909\n",
       "-0.0400  0.0009 -0.0988  ...   0.0423 -0.0371 -0.0146\n",
       "[torch.FloatTensor of size 51322x300]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss function\n",
    "# with smaller lr and add regularizaition\n",
    "best_model = model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4,weight_decay=1e-5)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 1:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Writing to /Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/runs/1523824793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/lstm.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs = F.log_softmax(y)\n",
      "Train epoch 1: 100%|██████████| 4049/4049 [46:34<00:00,  1.45it/s]\n",
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.97 acc 61.7 f1 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:89: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.16 acc 30.6 f1 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 2:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.16 acc 30.6 f1 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████| 4049/4049 [54:01<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.76 acc 71.4 f1 0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 3:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.30 acc 30.6 f1 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████| 4049/4049 [1:25:04<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.58 acc 79.2 f1 0.768\n",
      "Dev: loss 1.04 acc 60.2 f1 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 4:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.05 acc 60.2 f1 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████| 4049/4049 [1:09:21<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.44 acc 84.5 f1 0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 5:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.88 acc 31.1 f1 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████| 4049/4049 [1:10:26<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.35 acc 87.9 f1 0.871\n",
      "Dev: loss 0.99 acc 69.6 f1 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 6:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 0.97 acc 69.3 f1 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████| 4049/4049 [1:09:28<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.29 acc 90.0 f1 0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 7:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.69 acc 38.4 f1 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████| 4049/4049 [1:07:21<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.25 acc 91.1 f1 0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 8:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 0.93 acc 65.4 f1 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████| 4049/4049 [2:39:09<00:00,  2.36s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.22 acc 92.0 f1 0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 9:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 0.91 acc 62.2 f1 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████| 4049/4049 [3:30:42<00:00,  3.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.19 acc 92.6 f1 0.925\n",
      "Dev: loss 1.13 acc 71.9 f1 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 10:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.22 acc 70.4 f1 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 10: 100%|██████████| 4049/4049 [1:22:15<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.18 acc 93.3 f1 0.932\n",
      "Dev: loss 1.69 acc 52.8 f1 0.51\n",
      "Final Test: loss 1.91 acc 45.8 f1 0.43\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss, acc,f1 = train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\n",
    "    tqdm.write('Train: loss %.2f acc %.1f f1 %.3f' % (avg_loss, acc*100,f1))\n",
    "    dev_acc , dev_f1= evaluate(model, dev_iter, loss_function, 'Dev')\n",
    "    if dev_acc > best_dev_acc:\n",
    "        if best_dev_acc > 0:\n",
    "            os.system('rm '+ out_dir + '/best_model' + '.pth')\n",
    "        best_dev_acc = dev_acc\n",
    "        best_model = model\n",
    "        torch.save(best_model.state_dict(), out_dir + '/best_model' + '.pth')\n",
    "        # evaluate on test with the best dev performance model\n",
    "        test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Test')\n",
    "test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Final Test')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no emoji embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji dictionary load successfully\n",
      "word2vec load successfully\n",
      "emoji2vec set to 0 successfully\n",
      "emoticon2vec load successfully\n",
      "Loading complete\n"
     ]
    }
   ],
   "source": [
    "#load dictionary\n",
    "import pickle\n",
    "emoji_dict =pickle.load(open('./data/SST2/emoji_dict.p','rb'))\n",
    "print(\"emoji dictionary load successfully\")\n",
    "# load embedding\n",
    "word_to_idx = text_field.vocab.stoi\n",
    "pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n",
    "pretrained_embeddings[0] = 0\n",
    "#word2vec = load_bin_vec('./data/GoogleNews-vectors-negative300.bin', word_to_idx)\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word2vec= KeyedVectors.load_word2vec_format('./embedding/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "for word in word2vec.vocab:\n",
    "    pretrained_embeddings[word_to_idx[word]-1] = word2vec[word]\n",
    "print(\"word2vec load successfully\")\n",
    "emoji2vec =KeyedVectors.load_word2vec_format('./embedding/emoji2vec.bin', binary=True)\n",
    "for word in emoji2vec.vocab:\n",
    "    if word in emoji_dict.keys():\n",
    "        pretrained_embeddings[word_to_idx[emoji_dict[word]]-1] = np.zeros(300)\n",
    "print(\"emoji2vec set to 0 successfully\")\n",
    "emoticon2vec = KeyedVectors.load_word2vec_format('./embedding/emoticon2vec.txt', binary=False)\n",
    "\n",
    "\n",
    "\n",
    "for word in emoticon2vec.vocab:\n",
    "    pretrained_embeddings[word_to_idx[word]-1] = emoticon2vec[word]\n",
    "print(\"emoticon2vec load successfully\")    \n",
    "print('Loading complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 500\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "timestamp = str(int(time.time()))\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "\n",
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LSTMSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n",
    "                          use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.1256 -0.1908  0.0809  ...  -0.2132 -0.2020 -0.0540\n",
       " 0.0801  0.1050  0.0498  ...   0.0037  0.0476 -0.0688\n",
       "          ...             ⋱             ...          \n",
       " 0.0373 -0.0412  0.0839  ...  -0.0790 -0.2086 -0.1758\n",
       " 0.2105 -0.0310 -0.2465  ...   0.0832  0.2307 -0.0782\n",
       "-0.0400  0.0009 -0.0988  ...   0.0423 -0.0371 -0.0146\n",
       "[torch.FloatTensor of size 51322x300]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define optimizer and loss function\n",
    "best_model = model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 1:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Writing to /Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/runs/1523887552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/Desktop/NLP/project/model/pytorch-sentiment-classification-master/lstm.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs = F.log_softmax(y)\n",
      "Train epoch 1: 100%|██████████| 4049/4049 [50:00<00:00,  1.35it/s]\n",
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss 0.87 acc 66.4 f1 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihaozheng/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:89: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev: loss 1.28 acc 39.2 f1 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train epoch 2:   0%|          | 0/4049 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: loss 1.38 acc 33.7 f1 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2:   1%|          | 36/4049 [00:39<1:13:00,  1.09s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e7c02a99276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train: loss %.2f acc %.1f f1 %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdev_acc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdev_f1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-64bbd2a7d077>\u001b[0m in \u001b[0;36mtrain_epoch_progress\u001b[0;34m(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nihaozheng/anaconda/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for epoch in range(EPOCHS):\n",
    "    avg_loss, acc,f1 = train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\n",
    "    tqdm.write('Train: loss %.2f acc %.1f f1 %.3f' % (avg_loss, acc*100,f1))\n",
    "    dev_acc , dev_f1= evaluate(model, dev_iter, loss_function, 'Dev')\n",
    "    if dev_acc > best_dev_acc:\n",
    "        if best_dev_acc > 0:\n",
    "            os.system('rm '+ out_dir + '/best_model' + '.pth')\n",
    "        best_dev_acc = dev_acc\n",
    "        best_model = model\n",
    "        torch.save(best_model.state_dict(), out_dir + '/best_model' + '.pth')\n",
    "        # evaluate on test with the best dev performance model\n",
    "        test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Test')\n",
    "test_acc,test_f1 = evaluate(best_model, test_iter, loss_function, 'Final Test')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM.ipynb   \u001b[1m\u001b[31mREADME.md\u001b[m\u001b[m      \u001b[1m\u001b[36mdata\u001b[m\u001b[m           \u001b[1m\u001b[31mlstm.py\u001b[m\u001b[m\r\n",
      "LSTM.ipynb     \u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m    \u001b[1m\u001b[31mdata_helper.py\u001b[m\u001b[m \u001b[1m\u001b[36mruns\u001b[m\u001b[m\r\n",
      "Other ML.ipynb \u001b[1m\u001b[31mbilstm.py\u001b[m\u001b[m      \u001b[1m\u001b[36membedding\u001b[m\u001b[m      \u001b[1m\u001b[31mtrain_batch.py\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_batch.py\", line 160, in <module>\n",
      "    train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)\n",
      "  File \"train_batch.py\", line 131, in load_sst\n",
      "    label_field.build_vocab(train, dev, test)\n",
      "  File \"/Users/nihaozheng/anaconda/lib/python3.6/site-packages/torchtext/data/field.py\", line 248, in build_vocab\n",
      "    for x in data:\n",
      "  File \"/Users/nihaozheng/anaconda/lib/python3.6/site-packages/torchtext/data/dataset.py\", line 96, in __getattr__\n",
      "    yield getattr(x, attr)\n",
      "AttributeError: 'Example' object has no attribute 'label'\n"
     ]
    }
   ],
   "source": [
    "! python train_batch.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
